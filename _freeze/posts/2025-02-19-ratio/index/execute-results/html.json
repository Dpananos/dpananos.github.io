{
  "hash": "5d7fe10877e578e7ac052e1a425c4009",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Poop\ndate: \"2025-02-19\"\ncode-fold: true\necho: true\nfig-cap-location: top\ncategories: []\nnumber-sections: false\ndraft: false\ncache: true\n---\n\n\n# Introduction\n\nI work at Eppo now, by the way.  Eppo recently appeared in a [post by Simon Raper](https://glasseye.substack.com/p/glasseye-e42?open=false#%C2%A7the-dunghill) where he kind of poo-poo'd on us a little.  The gist is that Eppo's causal contrast of choice is the lift, which is\n\n$$ \\operatorname{lift} = \\dfrac{E[Y(1)] - E[Y(0)]}{E[Y(0)]} \\>. $$\n\nTo estimate the sampling variance of the lift, we rely fairly heavily on the CLT; with enough data, each mean is can be approximated as a normal random variable if we assume the standard deviation is equal to the sample standard error.  Judicious use of the delta method then gives us asymptotic variance estimates for the lift, and thereby confidence intervals.\n\nHowever, when the denominator is very close to 0 (perhaps in cases where conversion rates are very low), the lift can do weird things.  Just this past week I had to hop into a slack thread and explain to a customer that their lift wasn't actually 200%, they they just had 1 conversion in control and 3 conversions in treatment (also, stop peeking and just wait for the experiment to finish).\n\nTo prevent these sorts of false alarms, Eppo won't show an estimate of the lift unless the estimate of the control is 1.5 SDs away from 0. Where did 1.5 come from?  Not sure, before my time.  But Simon seems to take issue with it, writing\n\n>To be fair, [Eppo's] documentation comes with the caveat: “If the estimate for Control is close to zero, that ratio becomes unreliable. We do not compute the relative lift when Control is less than 1.5 standard deviation around zero.” Although it’s not exactly clear what this means. 1.5 standard deviation of which distribution? If they want to ensure that the inference works then wouldn’t be better to use the bounds given in the paper. And if they don’t use relative lift then what do they do? Revert to absolute lift? In which case what was the point of the whole exercise?\n\nThe paper Simon is citing is [this paper](https://www.researchgate.net/profile/F-Rubio/publication/257406150_On_the_existence_of_a_normal_approximation_to_the_distribution_of_the_ratio_of_two_independent_normal_random_variables/links/53d7a18a0cf2e38c632ddabc/On-the-existence-of-a-normal-approximation-to-the-distribution-of-the-ratio-of-two-independent-normal-random-variables.pdf), which examines how normal the density of two normals with positive means can really be.  He seems to think that the 1.5 SD criterion is too permissible and that we should use criteria provided in the linked paper.  I tend to agree, so do my colleagues (to various levels of zeal).\n\nThe linked paper's criteria for the ratio of two normals being \"normal enough\" is a function of the coefficient of variation for the denominator, which would be \n\n$$ \\delta_y = \\dfrac{\\sigma}{\\sqrt{n}\\mu} $$\n\nsince the standard deviation is the standard error.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(0)\n\nerf <- function(x) 2 * pnorm(x * sqrt(2)) - 1\nf_z <- function(z, beta, rho, delta_y){\n  \n  q <- (1 + beta*rho^2*z) / (delta_y * sqrt(1 + rho^2*z^2))\n  \n  term1 <- rho / (pi * (1 + rho^2*z^2))\n  term2 <- exp(-(1 + rho^2 * beta^2)/(2*delta_y^2))\n  term3 <- 1 + sqrt(pi/2)*q*erf(q / sqrt(2)) * exp(q^2/2)\n  \n  term1*term2*term3\n  \n}\n\n\np_control <- 0.1\ntrue_lift <- 1.05\np_treatment <- true_lift * p_control\nn <- 1000\nN <- 1000000\nv <- function(x) x*(1-x)\n\ntreatment <- rbinom(N, n, p_treatment) / n\ncontrol <- rbinom(N, n, p_control) / n\n\ndelta_y <- sqrt(v(p_control)/n) / p_control\nrho <- sqrt(v(p_control)) / sqrt(v(p_treatment))\n\nz <- seq(0, max(treatment/control), 0.01)\ny_true <- f_z(z, true_lift, rho, delta_y)\ny_approx <- dnorm(z, true_lift, sqrt(2*true_lift^2*delta_y^2))\n\nhist(treatment/control, probability = T, ylim = c(0, max(max(y_approx), max(y_true))), main=\"\", xlab = \"Ratio of sample means\")\nlines(z, y_true, col='red', lwd=2)\nlines(z, y_approx, col='blue', lwd=2, lty=2)\nlegend(\"topright\", legend = c(\"True Density\", \"Normal Approximation\"), col = c(\"red\", 'blue'), lty = c(1, 2), lwd = c(2, 2), cex = 0.8)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow = c(3, 3))\n\nvals <- 4:12\ncv_vals <- 1.0 / vals\nz <- seq(0, 4, 0.01)\nbeta <- 1.5\nrho <- 1.0\n\nfor(cv in cv_vals){\n  \n  plot(z,\n       f_z(z, beta, rho, cv),\n       type = 'l',\n       main = bquote(delta[y] == .(round(cv, 3))),\n       ylab = expression(f[z](1.5, 1, delta[y])),\n       lwd=2, col='red'\n       )\n  \n  norm_var <- beta^2 * (cv^2 + rho^2 * cv^2/beta^2)\n  \n  lines(z, dnorm(z, beta, sqrt(norm_var)), lwd=2, col='blue', lty=2)\n}\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-2-1.png){width=960}\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}